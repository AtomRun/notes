# HashMap

HashMap是java中以一个键值对形式存储的集合，存储删除速度和查询修改速度都很快

# 为什么HashMap存取都很快？

1. 原因是因为底层数据结构使用了数组+链表的形式(1.7)
2. jdk1.8使用了数组+链表+红黑树。如果比较发现链表的长度已经大于map中定义的TREEIFY_THRESHOLD - 1的话，也就是7，就会将链表转换为红黑树，将数据存到红黑树中，这里为什么要减掉1呢，其实这块也是面试官必问的，也就是我刚开始提到的一个面试题:什么时候链表会转换成红黑树? map里面定义的是8，这里减了1.是因为在我们进行遍历链表之前，我们已经取出来了数组上面的第一个链表元素了，后面的遍历是基于这个元素的next进行遍历的，所以这里就需要将TREEIFY_THRESHOLD-1作为转换条件判断。
3. 但是当执行resize操作时，当桶中元素的数量少于UNTREEIFY_THRESHOLD时使用链表来代替树即退化，UNTREEIFY_THRESHOLD默认值为6
4. 当我们取值的时候，直接将key的hashcode与数组长度拿到下标，这样的话取值就是(O)1。
5. 使用数组+链表的话，当链表过长，HashMap读很长的链表需要遍历，时间复杂度退化，这个时候就引申出来红黑树了。

# HashMap怎么计算下标的？

## 首先我们来看hash方法，即如何将key转换为hashcode

```java
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

首先判断了key是否为空，不为空就调用了key的hashcode方法赋值给h并且和h右移16位后的h再次进行异或运算即用h的低位异或h的高位

![hashmap](https://pic3.zhimg.com/80/4acf898694b8fb53498542dc0c5f765a_720w.jpg?source=1940ef5c)

右位移16位，正好是32bit的一半，自己的高半区和低半区做异或，就是为了混合原始哈希码的高位和低位，以此来加大低位的随机性。而且混合后的低位掺杂了高位的部分特征，这样高位的信息也被变相保留下来。

## HashMap计算下标的时候是在putVal的时候

```java
if ((p = tab[i = (n - 1) & hash]) == null)
    tab[i] = newNode(hash, key, value, null);
```

```java
i = (n-1) & hash
```

i就是下标，下标的计算方式为数组长度&hash值。

# 为什么每次是2的整数次幂进行扩容？

首先每次扩容都是当前容量的两倍，例如16->32->64

 比如： 

十进制: 201314 

二进制: 11 0001 0010 0110 0010

**假设初始化大小为16**

15转化为二进制: 1111

index : 11 0001 0010 0110 0010 & 1111 =0010 为 3 

**假设初始化大小为10**

10转化为二进制: 1010

index: 11 0001 0010 0110 0010 & 1010=0010 为 3

因为是将二进制进行按位于，(16-1) 是 1111,**末位是1**，这样也能保证计算后的index既可以是奇数也可以是偶数，并且只要传进来的key足够分散，均匀那么按位于的时候获得的index就会减少重复，这样也就减少了hash的碰撞以及hashMap的查询效率。

那么到了这里你也许会问？ 那么就然16可以，是不是只要是2的整数次幂就可以呢？

答案是肯定的。那为什么不是8,4呢？ 因为是8或者4的话很容易导致map扩容影响性能，如果分配的太大的话又会浪费资源，所以就使用16作为初始大小

# 为什么需要length-1？

## 1. 保证元素尽可能的均匀分布

由上边的分析可知，length一定是一个偶数，length - 1一定是一个奇数。假设现在数组的长度length为16，减去1后length - 1就是15，15对应的二进制是：1111。现在假设有两个元素需要插入，一个哈希值是8，二进制是1000，一个哈希值是9，二进制是1001。和1111“与”运算后，结果分别是1000和1001，它们被分配在了数组的不同位置，这样，哈希的分布非常均匀。那么，如果数组长度是奇数呢？减去1后length - 1就是偶数了，偶数对应的二进制最低位一定是 0，例如14二进制1110。对上面两个数子分别“与”运算，得到1000和1000。结果都是一样的值。那么，哈希值8和9的元素都被存储在数组同一个index位置的链表中。在操作的时候，链表中的元素越多，效率越低，因为要不停的对链表循环比较。

## 2. 保证不会发生数组越界

首先我们要知道的是，在HashMap，数组的长度按规定一定是**2的幂**。因此，数组的长度的二进制形式是：10000…000, 1后面有偶数个0。 那么，length - 1 的二进制形式就是01111.111, 0后面有偶数个1。最高位是0, 和hash值相“与”，结果值一定不会比数组的长度值大，因此也就不会发生数组越界。

# 为什么HashMap默认大小为16

因为负载因子的缘故，如果容量太小，就会频繁发生扩容，扩容很影响性能，因为每次扩容要进行rehash。rehash的原因是因为，我们的下标都是根据长度来的，扩容之后长度发生了变化，所以要rehash

如果容量设置太大浪费空间，不划算。

# 为什么重写HashCode必须要重写equals

首先我们必须要知道，每个类都是继承了Object父类，假设我们不重写Hashcode和Equals，那么就会调用父类的hashcode和equals。父类的hashcode使用了navtive的hashcode方法，将对象的地址调用hashcode方法返回的值作为hashcode。

在这种情况下如果我们不重写equals就会出问题，因为默认的equals还是调用比较地址的“==”，假设两个对象进行hashcode地址相同，也没有重写equals。本身内容不同，但是equals比较的是地址，这个时候就会出问题

# HashMap什么时候扩容？为什么负载因子是0.75？

HashMap有一个参数为`loadFactor`，即负载因子

```java
    /**
     * The load factor used when none specified in constructor.
     */
    static final float DEFAULT_LOAD_FACTOR = 0.75f;
```

当数组的长度大于当前数组长度的0.75的时候，即假设数组长100，大于75的时候，就会扩容。

因为：是均衡了时间和空间损耗算出来的值，较高的值会减少空间开销（扩容减少，数组大小增长速度变慢），但增加了查找成本（hash 冲突增加，链表长度变长），不扩容的条件：数组容量 > 需要的数组大小 /load factor

# HashMap什么时候链表转换为红黑树

链表长度>8且 数组长度>64的时候

# 为什么链表长度为8且数组长度64再扩容？

链表查询的时间复杂度是 O (n)，红黑树的查询复杂度是 O (log (n))。在链表数据不多的时候，使用链表进行遍历也比较快，只有当链表数据比较多的时候，才会转化成红黑树，但红黑树需要的占用空间是链表的 2 倍，考虑到转化时间和空间损耗，所以我们需要定义出转化的边界值。

在考虑设计 8 这个值的时候，我们参考了泊松分布概率函数，由泊松分布中得出结论，链表各个长度的命中概率为：

```text
* 0:    0.60653066
* 1:    0.30326533
* 2:    0.07581633
* 3:    0.01263606
* 4:    0.00157952
* 5:    0.00015795
* 6:    0.00001316
* 7:    0.00000094
* 8:    0.00000006
```

意思是，当链表的长度是 8 的时候，出现的概率是 0.00000006，不到千万分之一，所以说正常情况下，链表的长度不可能到达 8 ，而一旦到达 8 时，肯定是 hash 算法出了问题，所以在这种情况下，为了让 HashMap 仍然有较高的查询性能，所以让链表转化成红黑树，我们正常写代码，使用 HashMap 时，几乎不会碰到链表转化成红黑树的情况，毕竟概念只有千万分之一。

# HashMap数组的最大长度

2的30次方